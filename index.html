
<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>three.js - depth camera</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body {
				font-family: Monospace;
				background-color: #000000;
				margin: 0px;
				overflow: hidden;
			}

			#videoSelect {
				color: #ffffff;

				font-family: Monospace;
				font-size: 13px;
				text-align: center;
				font-weight: bold;

				position: absolute;
				top: 0px; width: 100%;
				padding: 5px;
			}

			video {
				position: absolute;
				bottom: 0px; left: 0px;
				width: 20%;
				height: 20%;
			}

			a {

				color: #0040ff;

			}
		</style>
	</head>
	<body>
		<a href="https://github.com/huningxin/depthcam_three.js/"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/e7bbb0521b397edbd5fe43e7f760759336b5e05f/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677265656e5f3030373230302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png"></a>
		<div class='select' id='videoSelect'>
		  <label for='videoSource'>Video source: </label><select id='videoSource'></select>
		</div>
		<script src="build/three.min.js"></script>

		<script src='js/libs/dat.gui.min.js'></script>

		<script src="js/Detector.js"></script>
		<script src="js/libs/stats.min.js"></script>

		<script id="vs" type="x-shader/x-vertex">

			uniform sampler2D map;

			uniform float width;
			uniform float height;
			uniform float nearClipping, farClipping;

			uniform float pointSize;
			uniform float zOffset;

			varying vec2 vUv;
			varying float depth;

			const float XtoZ = 1.11146; // tan( 1.0144686 / 2.0 ) * 2.0;
			const float YtoZ = 0.83359; // tan( 0.7898090 / 2.0 ) * 2.0;
			const float max = 3000.;
			const float min = 150.;
			const float np = 512.;
			const float w = max;

			// Implement the depth decode scheme proposed in paper
			// "Adapting Standard Video Codecs for Depth Streaming"
			float decodeAdaptiveDepth(vec4 rgba) {
				float L = rgba.b;
				float Ha = rgba.g;
				float Hb = rgba.r;
				float p = np / w;

				float m = mod(floor( 4. * L / p - 0.5 ), 4.);
				float q;
				if (m == 0.) {
					q = p / 2. * Ha;
				} else if (m == 1.) {
					q = p / 2. * Hb;
				} else if (m == 2.) {
					q = p / 2. * (1. - Ha);
				} else if (m == 3.) {
					q = p / 2. * (1. - Hb);
				}

				float l = L - (mod(L - p / 8., p)) + p / 4. * m - p / 8.;

				float d = w * (l + q);
				if (d < min)
					return 1.0;
				else
					return (l + q);
				return 1.0;
			}

			void main() {

				vUv = vec2( position.x / width, position.y / height );

				vec4 color = texture2D( map, vUv );

				depth = decodeAdaptiveDepth(color);

				// Projection code by @kcmic

				float z = depth * (farClipping - nearClipping) + nearClipping;

				vec4 pos = vec4(
					( position.x / width - 0.5 ) * z * XtoZ,
					( position.y / height - 0.5 ) * z * YtoZ,
					- z + zOffset,
					1.0);

				gl_PointSize = pointSize;
				gl_Position = projectionMatrix * modelViewMatrix * pos;

			}

		</script>

		<script id="fs" type="x-shader/x-fragment">

			uniform sampler2D map;

			varying vec2 vUv;
			varying float depth;

			void main() {
				vec4 color = texture2D( map, vUv );
				if (depth > 0.99)
					discard;

				gl_FragColor = vec4( 0.5, 0.5, 0.5, 0.5 );

			}

		</script>

		<script>

			var container;

			var scene, camera, light, renderer;
			var geometry, cube, mesh, material;
			var mouse, center;
			var stats, gui;
			var intervalId, animationId;

			var video, texture;
			var stream;

			var videoSelect = document.querySelector("select#videoSource");

			navigator.getUserMedia = navigator.getUserMedia ||
				navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

			if ( Detector.webgl ) {

				start();

			} else {

				document.body.appendChild( Detector.getWebGLErrorMessage() );

			}

			function gotSources(sourceInfos) {
			  for (var i = 0; i != sourceInfos.length; ++i) {
				var sourceInfo = sourceInfos[i];
				var option = document.createElement("option");
				option.value = sourceInfo.id;
				if (sourceInfo.kind === 'audio') {
				  console.log('Not use microphone.');
				} else if (sourceInfo.kind === 'video') {
				  option.text = sourceInfo.label || 'camera ' + (videoSelect.length + 1);
				  videoSelect.appendChild(option);
				} else {
				  console.log('Some other kind of source: ', sourceInfo);
				}
			  }
			}

			if (typeof MediaStreamTrack === 'undefined'){
			  alert('This browser does not support MediaStreamTrack.\n\nTry Chrome Canary.');
			} else {
			  MediaStreamTrack.getSources(gotSources);
			}


			function successCallback(stream) {
			  window.stream = stream; // make stream available to console
			  init(stream);
			  animate();
			}

			function errorCallback(error){
			  console.log("navigator.getUserMedia error: ", error);
			}

			function start(){
			  if (!!window.stream) {
				video.src = null;
				window.stream.stop();
				clearInterval(intervalId);
				cancelAnimationFrame(animationId);
				document.body.removeChild(container);
				document.body.removeChild(video);
				document.body.removeChild(gui.domElement);
			  }
			  var videoSource = videoSelect.value;
			  var constraints = {
				video: {
				  optional: [{sourceId: videoSource}]
				}
			  };
			  constraints = {video: { "mandatory": { "depth": true}}};
			  navigator.getUserMedia(constraints, successCallback, errorCallback);
			}

			videoSelect.onchange = start;

			function init(stream) {

				container = document.createElement( 'div' );
				document.body.appendChild( container );

				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				container.appendChild( stats.domElement );

				camera = new THREE.PerspectiveCamera( 50, window.innerWidth / window.innerHeight, 1, 10000 );
				camera.position.set( 0, 0, 500 );

				scene = new THREE.Scene();
				center = new THREE.Vector3();
				center.z = - 1000;

				video = document.createElement( 'video' );
				video.addEventListener( 'loadedmetadata', function ( event ) {

					texture = new THREE.Texture( video );

					var width = 640, height = 480;
					var nearClipping = 850, farClipping = 4000;

					geometry = new THREE.Geometry();

					for ( var i = 0, l = width * height; i < l; i ++ ) {

						var vertex = new THREE.Vector3();
						vertex.x = ( i % width );
						vertex.y = Math.floor( i / width );

						geometry.vertices.push( vertex );

					}

					material = new THREE.ShaderMaterial( {

						uniforms: {

							"map": { type: "t", value: texture },
							"width": { type: "f", value: width },
							"height": { type: "f", value: height },
							"nearClipping": { type: "f", value: nearClipping },
							"farClipping": { type: "f", value: farClipping },

							"pointSize": { type: "f", value: 2 },
							"zOffset": { type: "f", value: 300 }

						},
						vertexShader: document.getElementById( 'vs' ).textContent,
						fragmentShader: document.getElementById( 'fs' ).textContent,
						depthTest: false, depthWrite: false,
						transparent: true

					} );

					mesh = new THREE.ParticleSystem( geometry, material );
					mesh.position.x = 0;
					mesh.position.y = 0;
					scene.add( mesh );

					intervalId = setInterval( function () {

						if ( video.readyState === video.HAVE_ENOUGH_DATA ) {

							texture.needsUpdate = true;

						}

					}, 1000 / 30 );


					gui = new dat.GUI({autoPlace: false});
					document.body.appendChild(gui.domElement);
					gui.domElement.style.position = "absolute";
					gui.domElement.style.top = "0px";
					gui.domElement.style.right = "5px";
					gui.add( material.uniforms.nearClipping, 'value', 1, 10000, 1.0 ).name( 'nearClipping' );
					gui.add( material.uniforms.farClipping, 'value', 1, 10000, 1.0 ).name( 'farClipping' );
					gui.add( material.uniforms.pointSize, 'value', 1, 10, 1.0 ).name( 'pointSize' );
					gui.add( material.uniforms.zOffset, 'value', 0, 4000, 1.0 ).name( 'zOffset' );
					gui.close();


				}, false );
				video.loop = true;
				video.src = window.URL.createObjectURL(stream);
				video.play();
				document.body.appendChild(video);

				renderer = new THREE.WebGLRenderer();
				renderer.setSize( window.innerWidth, window.innerHeight );
				container.appendChild( renderer.domElement );

				mouse = new THREE.Vector3( 0, 0, 1 );

				document.addEventListener( 'mousemove', onDocumentMouseMove, false );

				//

				window.addEventListener( 'resize', onWindowResize, false );

			}

			function onWindowResize() {

				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();

				renderer.setSize( window.innerWidth, window.innerHeight );

			}

			function onDocumentMouseMove( event ) {

				mouse.x = ( event.clientX - window.innerWidth / 2 ) * 8;
				mouse.y = ( event.clientY - window.innerHeight / 2 ) * 8;

			}

			function animate() {

				animationId = requestAnimationFrame( animate );

				render();
				stats.update();

			}

			function render() {

				camera.position.x += ( mouse.x - camera.position.x ) * 0.05;
				camera.position.y += ( - mouse.y - camera.position.y ) * 0.05;
				camera.lookAt( center );

				renderer.render( scene, camera );

			}

		</script>
	</body>
</html>
